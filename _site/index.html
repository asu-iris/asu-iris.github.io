<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

    IRIS Lab


</title>
<!-- <meta name="description" content=""> -->

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
<link href="//cdnjs.cloudflare.com/ajax/libs/academicons/1.9.2/css/academicons.min.css" rel="stylesheet" >
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->

<!-- Styles -->
<!-- 
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
i
 -->

<link rel="icon" type="image/png" href="/collections/photo/group/lab_logo.png">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    

<header>


  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">


    <!-- <nav id="navbar" class="navbar navbar-light navbar-expand-sm "> -->



      <div class="container">


        <a class="navbar-brand" href="../">
          <img id="logo-main" base src="/assets/img/lab_logo.png" width="250" alt="Logo Thing main logo"><br>
        </a>


        <!-- Navbar Toggle -->

        <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar top-bar"></span>
          <span class="icon-bar middle-bar"></span>
          <span class="icon-bar bottom-bar"></span>
        </button>


        <div class="collapse navbar-collapse text-right" id="navbarNav">
          <ul class="navbar-nav mx-auto flex-nowrap">




            <!-- About -->
<!--             <li class="nav-item active">
              <a class="nav-link" href="/">
                about
                
                <span class="sr-only">(current)</span>
                
              </a>
            </li> -->

            <!-- Other pages -->
            
            
            
            
            
            
            <li class="nav-item ">
              <a class="nav-link" href="/research/">
                research
                
              </a>
            </li>
            
            
            
            
            
            <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
            </li>
            
            
            
            
            
            <li class="nav-item ">
              <a class="nav-link" href="/people/">
                people
                
              </a>
            </li>
            
            
            
            
            
            <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
            </li>
            
            
            
            
            
            <li class="nav-item ">
              <a class="nav-link" href="/robots/">
                lab
                
              </a>
            </li>
            
            
            
            
            
            <li class="nav-item ">
              <a class="nav-link" href="/joining/">
                joining
                
              </a>
            </li>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          </ul>
        </div>
      </div>
    </nav>

  </header>




    <!-- Content -->

    <div class="container mt-5">
      <article>
  <p>This is <strong>Intelligent Robotics and Interactive Systems (IRIS)</strong> Lab! Our research focuses include</p>

<ul>
  <li>
    <p><strong>Contact-rich manipulation:</strong> We develop efficient physics-based representations/modeling, planning/control methods to enable robots to gain dexterity through frequently making or breaking contacts with objects.</p>
  </li>
  <li>
    <p><strong>Human-autonomy alignment:</strong>  We develop certifiable, efficient, and empowering methods to enable robots to align their autonomy with human users through various natural interactions.</p>
  </li>
  <li>
    <p><strong>Fundamental computational methods:</strong> We develop fundamental algorithms for  efficient, safe, and robust robot intelligence, by harnessing the complementary benefits of model-based and data-driven approaches.</p>
  </li>
</ul>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>

<center>
    <a href="mailto:wanxin.jin@asu.edu" target="_blank"> 
    <img src="assets/img/email_logo.png" width="40" target="_blank" /> </a>   &nbsp;&nbsp;&nbsp;
<a href="https://scholar.google.com/citations?user=SoEC4h4AAAAJ&amp;hl=en" target="_blank"> 
    <img src="assets/img/scholar_logo.png" width="40" target="_blank" /></a>   &nbsp;&nbsp;&nbsp;
<a href="https://github.com/asu-iris" target="_blank">
    <img src="assets/img/github_logo.png" width="40" target="_blank" /></a> &nbsp;&nbsp;&nbsp;
<a href="https://twitter.com/jinwanxin" target="_blank">
    <img src="assets/img/twitter_logo.png" width="40" target="_blank" /></a>  &nbsp;&nbsp;&nbsp;
<a href="https://www.youtube.com/@robotics-iris-lab" target="_blank">
    <img src="assets/img/youtube_logo.png" width="40" target="_blank" /></a>  &nbsp;&nbsp;&nbsp;

</center>

<p><br /></p>

<h3 id="recent-updates"><strong>Recent Updates</strong></h3>

<p style="margin-bottom:0.6cm"> </p>

<div class="update-item">
    <div class="update-date">April 11, 2025</div>
      <div class="update-content">
      <p>
         Wanxin will gave a talk at RSS 2025 Workshop on Human-Robot Contact and Manipulation (HRCM 2025): <a href="https://hrcm-workshop.github.io/2025/" target="_blank">https://hrcm-workshop.github.io/2025/</a>. 
      </p> 
      </div>
  </div>
<hr />

<div class="update-item">
    <div class="update-date">April 11, 2025</div>
      <div class="update-content">
      <p>
         Our paper <a href="https://arxiv.org/pdf/2408.07855" target="_blank">‚ÄúComplementarity-Free Multi-Contact Modeling and Optimization for Dexterous Manipulation‚Äù</a> has been accepted to Robotics: Science and Systems (RSS) 2025. Congrats „äóÔ∏è üéâüéâüéâ!
      </p> 
        See our previous  
        <a href="https://x.com/jinwanxin/status/1825958958382854247" target="_blank" role="button"> <i class="fa-brands fa-twitter fa-shake"></i> ùïè-Twitter </a> and 
        <a href="https://www.youtube.com/watch?v=NsL4hbSXvFg" target="_blank" role="button"> <i class="fa-brands fa-youtube fa-shake"></i> YouTube </a> for an extended demo.
      </div>
  </div>
<hr />

<div class="update-item">
    <div class="update-date">Mar. 20, 2025</div>
      <div class="update-content">
      <p>
         Wanxin gave a talk at Penn State: <b>Toward Efficient &amp; Real-time Robotic Dexterity
         A physics contact approach for control, learning, &amp; perception</b>. Talk slides will be released soon!
      </p> 
      </div>
  </div>
<hr />

<div class="update-item">
    <div class="update-date">Feb 16, 2025</div>
      <div class="update-content">
      <p>
         Wen's paper <a href="https://arxiv.org/abs/2408.09612" target="_blank">‚ÄúContactSDF: Signed Distance Functions as Multi-Contact Models for Dexterous Manipulation‚Äù</a> has been accepted to RA-L. Congrats „äóÔ∏è to Wen üéâüéâüéâ!
      </p> 
        See our previous  
        <a href="https://x.com/jinwanxin/status/1828130385806651428" target="_blank" role="button"> <i class="fa-brands fa-twitter fa-shake"></i> ùïè-Twitter </a> and 
        <a href="https://youtu.be/2AsMYCT-jQI?si=yPK3kec3lj-85kts" target="_blank" role="button"> <i class="fa-brands fa-youtube fa-shake"></i> YouTube </a> for a brief introduction.
        <!-- <div class="video-container">
          <video autoplay loop muted controls>
            <source src="/collections/research/manipulation/contactsdf/contactSDF-media.mp4" type="video/mp4">
          </video>
        </div>
        <br>
          Check out the <a href="https://yangwen-1102.github.io/contactsdf.github.io/" target="_blank"> webpage</a>,  <a href="https://arxiv.org/abs/2408.09612" target="_blank">preprint</a>, and <a href="https://github.com/asu-iris/ContactSDF" target="_blank">code</a>. Here is a long demo:
        <br> <br> 
        <div class="video-container">
          <iframe src="https://www.youtube.com/embed/2AsMYCT-jQI?si=_7Y9LgnSfuF8yIoL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div> -->

      </div>
  </div>
<hr />

<div class="updates-list">


  <div class="update-item">
    <div class="update-date">Oct 15, 2024</div>
    <div class="update-content">
      <a href="https://x.com/adcock_brett/status/1848032460023468508" target="_blank" role="button"> <i class="fa-brands fa-twitter fa-shake"></i> ùïè-Twitter </a>
      <p>
      üî•üî• <strong>‚ÄúSkills from YouTube, No Prep!‚Äù</strong> üî•üî•
      Can robots learn skills from YouTube without complex video processing?
      Our <a href="https://arxiv.org/abs/2410.09286" target="_blank">"Language-Model-Driven Bi-level Method‚Äù</a>  makes it possible! By chaining VLM &amp; LLM in a bi-level framework, we use the ‚Äúchain rule‚Äù to guide reward learning directly from video demos. üöÄCheck out our RL agents mastering skills from their biological counterparts!üöÄ
      </p>
      <div class="video-container">
        <video autoplay="" loop="" muted="" controls="">
          <source src="/collections/research/human/lfd-llm/lfd-llm.mp4" type="video/mp4" />
        </video>
      </div>
      <br />
        Check out the <a href="https://arxiv.org/abs/2410.09286" target="_blank">preprint</a>. Here is a long demo:
      <br /> <br /> 
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/CzlyYLu4mLQ?si=jyh1nZdADkGYpAAQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
      </div>
    </div>
  </div>



<br /><br /><br />




  <div class="update-item">
    <div class="update-date">Aug 24, 2024</div>
    <div class="update-content">
      <a href="https://x.com/jinwanxin/status/1828130385806651428" target="_blank" role="button"> <i class="fa-brands fa-twitter fa-shake"></i> ùïè-Twitter </a>
      <p>
        üöÄ Can a robotic hand master dexterous manipulation  <strong>in just 2 minutes</strong>? YES! üéâ Excited to share our recent work  <a href="https://arxiv.org/abs/2408.09612" target="_blank">‚ÄúContactSDF‚Äù</a>, a physics-inspired representation using signed distance functions (SDFs) for contact-rich manipulation, from geometry to MPC. üî• Watch <strong>a full, uncut video</strong> of Allegro hand learning from scratch below!   We are pushing the boundaries of ‚Äúfast‚Äù learning and planning in dexterous manipulation.
      </p>
      <div class="video-container">
        <video autoplay="" loop="" muted="" controls="">
          <source src="/collections/research/manipulation/contactsdf/contactSDF-media.mp4" type="video/mp4" />
        </video>
      </div>
      <br />
        Check out the <a href="https://yangwen-1102.github.io/contactsdf.github.io/" target="_blank"> webpage</a>,  <a href="https://arxiv.org/abs/2408.09612" target="_blank">preprint</a>, and <a href="https://github.com/asu-iris/ContactSDF" target="_blank">code</a>. Here is a long demo:
      <br /> <br /> 
      <div class="video-container">
        <iframe src="https://www.youtube.com/embed/2AsMYCT-jQI?si=_7Y9LgnSfuF8yIoL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
      </div>
    </div>
  </div>



<br /><br /><br />

  <div class="update-item">
    <div class="update-date">Aug 19, 2024</div>
    <div class="update-content">
      <a href="https://x.com/jinwanxin/status/1825958958382854247" target="_blank" role="button"> <i class="fa-brands fa-twitter fa-shake"></i> ùïè-Twitter </a>
      <p>
      Can model-based planning and control rival or even surpass reinforcement learning in challenging dexterous manipulation tasks? Our answer is a resounding YES! PROUD to share: üî•üî•<a href="https://arxiv.org/abs/2408.07855" target="_blank">"Complementarity-Free Multi-Contact Modeling and Optimization,"</a>,  our latest method that sets shattering benchmarks in various challenging dexterous manipulation tasks.
      </p>
      <p> <a href="https://arxiv.org/abs/2408.07855" target="_blank">"Complementarity-Free Multi-Contact Modeling and Optimization,"</a>  consistently achieves state-of-the-art results across different challenging dexterous manipulation tasks, including fingertip 3D in-air manipulation, TriFinger in-hand manipulation, and Allegro hand on-palm manipulation, all with different objects. Check out the demo below!
      </p>
      Our method sets a new benchmark in dexterous manipulation:
      <ul>
        <li>üéØ A 96.5% success rate across all tasks</li>
        <li>‚öôÔ∏è High manipulation accuracy: 11¬∞ reorientation error &amp; 7.8 mm position error</li>
        <li>üöÄ Model predictive control running at 50-100 Hz for all tasks</li>
      </ul>
      <div class="video-container">
        <video autoplay="" loop="" muted="" controls="">
          <source src="/collections/research/manipulation/teaser-grid.mp4" type="video/mp4" />
        </video>
      </div>
      <br />
        Check out our <a href="https://arxiv.org/abs/2408.07855" target="_blank"> preprint</a>, and try out our  <a href="https://github.com/asu-iris/Complementarity-Free-Dexterous-Manipulation" target="_blank">code</a> (fun guaranteed). Here is a long demo:
      <br /> <br /> 
      <div class="video-container">
        <iframe src="https://www.youtube.com/embed/NsL4hbSXvFg?si=eICS9JW-ZxMTxOtm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
      </div>
    </div>
  </div>



<br /><br /><br />
  <div class="update-item">
    <div class="update-date">July 9 2024</div>
    <div class="update-content">
      <a href="https://x.com/jinwanxin/status/1815216477748019473" target="_blank" role="button"> <i class="fa-brands fa-twitter fa-shake"></i> ùïè-Twitter </a>
      <p>
        ü§ñ Robots may be good at inferring a task reward from human feedback, but how about inferring safety boundaries from human feedback? In many cases such as robot feeding and liquid pouring, specifying  user-comfortable safety constraints is more challenging  than  rewards. Our recent work, led by my PhD student <a href="https://zhi-xian-xie.github.io/" target="_blank">Zhixian Xie</a>,  shows that this is possible, and can actually be very human-effort efficient! Our method is called <a href="https://arxiv.org/abs/2407.04216" target="_blank">Safe MPC Alignment</a> (submitted to T-RO), enabling a robot to learn its control safety constraints with only a small handful of human online corrections!
      </p>
      Importantly, the Safe MPC Alignment is certifiable: providing an upper bound on the total number of human feedback in the case of successful learning of safety constraints, or declaring the misspecification of the hypothesis space, i.e., the true implicit safety constraint cannot be found within the specified hypothesis space. 
      <div class="video-container">
        <video autoplay="" loop="" muted="" controls="">
          <source src="/collections/research/human/media-robot.mp4" type="video/mp4" />
        </video>
      </div>
      <br />
      Check out the <a href="https://zhi-xian-xie.github.io/safe_alignment_site/" target="_blank">project website</a>, <a href="https://arxiv.org/abs/2407.04216" target="_blank"> preprint</a>, and a breaf introduction vide below.
      <br /> 
      <div class="video-container">
        <iframe src="https://www.youtube.com/embed/QOODShHLQJE?si=IuYvkp3wm507Dc2Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
      </div>
    </div>
  </div>

  <!-- Add more update items as needed -->
</div>


</article>



    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025   IRIS Lab.
    
    
    
    Last updated: April 11, 2025.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
